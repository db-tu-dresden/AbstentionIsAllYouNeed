{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb92ca-97a2-484f-9324-d0252af13b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "#from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, AutoConfig\n",
    "from transformers import AutoModel\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "\n",
    "from dependencies.basic_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea81510-f646-40da-b8f9-fe3b6ff026e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dependencies.basic_functions\n",
    "importlib.reload(dependencies.basic_functions)\n",
    "\n",
    "from dependencies.basic_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f82939-6251-4042-860e-5c9e30fdb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGED ALLE RESULT FILE IN /RESULTS\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define the folder path\n",
    "results_folder = './results'\n",
    "\n",
    "# Initialize the lists\n",
    "full_df_list = []\n",
    "time_df_list = []\n",
    "ROC_DICT_list = []\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for file_name in os.listdir(results_folder):\n",
    "    if file_name.startswith(\"results_\") and file_name.endswith(\".pkl\"):\n",
    "        file_path = os.path.join(results_folder, file_name)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            # Append to the respective lists\n",
    "            if isinstance(data, dict) and {'full_df', 'time_df', 'ROC_DICT'}.issubset(data.keys()):\n",
    "                dataset_name_tmp = data['full_df'][\"Dataset\"].iloc[0] + ' Interpolated' #Zum Mergen mit TimeDF später\n",
    "                data['time_df'][\"Dataset\"] = dataset_name_tmp\n",
    "                full_df_list.append(data['full_df'])\n",
    "                time_df_list.append(data['time_df'])\n",
    "                ROC_DICT_list.append(data['ROC_DICT'])\n",
    "            else:\n",
    "                print(f\"File {file_name} does not have the expected structure.\")\n",
    "\n",
    "df = pd.concat(full_df_list, ignore_index=True)\n",
    "time_result = pd.concat(time_df_list, ignore_index=True)\n",
    "\n",
    "big_ROC_dict = {}\n",
    "for roc_dict in ROC_DICT_list:\n",
    "    for dataset_name, content in roc_dict.items():\n",
    "        # Add the dataset_name and content to the big dictionary\n",
    "        big_ROC_dict[dataset_name] = content\n",
    "\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import simps\n",
    "#Interpolate -> Dann 0.0,0.05,0.1 ... 1.0 Coverage Umwandeln für Merge\n",
    "#Interpolate hat probleme bei duplicates\n",
    "\n",
    "\n",
    "\n",
    "interpolated_dataframes = []\n",
    "#Method_Classifier \tDataset \tMethod \tData_size \tClassifier\n",
    "score_df = pd.DataFrame(columns=[\"Method_Classifier\", \"Dataset\",\"Data_size\",\"Score_50\",\"Score_90\",\"Score_95\",\"Method\",\"Classifier\"])\n",
    "\n",
    "for size in df.Data_size.unique():\n",
    "\n",
    "    for methode_clf in df.Method_Classifier.unique():\n",
    "        dff = df[df['Data_size'] == size]\n",
    "        #Maybe noch 1->0.5 cov only\n",
    "        dff = dff[dff['Method_Classifier'] == methode_clf]\n",
    "        if dff.empty: #(Leer -> z.B. Nicht volle Runs/alle Methoden gemacht mit 10k size)\n",
    "                continue\n",
    "                \n",
    "        methode = dff[\"Method\"].iloc[0]\n",
    "        clf_name = dff[\"Classifier\"].iloc[0]\n",
    "        \n",
    "        for dataset in df.Dataset.unique():\n",
    "            dffd = dff[dff['Dataset'] == dataset] #error da dataset sentiment ausgewählt wird? warum nur agnews error\n",
    "\n",
    "            if dffd.empty: #(Leer -> z.B. Nicht volle Runs/alle Methoden gemacht mit 10k size)\n",
    "                continue \n",
    "\n",
    "            #DROPOUT METHOD, ALLGEMEIN METHODEN DIE NICHT BIS ZUM ENDE CONVERAGE LINIE ZIEHEN AKA SICH NICHT SINNVOLL APPROXIMIEREN LASSEN\n",
    "            #      ->WORKAROUND, LETZTEN ACCURACY WERT z.B. BEI 0.7 COVERAGE DANN AUCH BEI 0.0\n",
    "            if methode_clf == \"Dropout Agreement MV generic\" or methode_clf == \"Dropout Agreement DP generic\":\n",
    "                #print(dffd[\"Coverage\"].values[-1], dffd[\"Accuracy\"].values[-1])\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"Coverage\": 0.0,\n",
    "                    \"Accuracy\": dffd[\"Accuracy\"].values[-1]\n",
    "                }])\n",
    "                dffd = pd.concat([dffd, new_row], ignore_index=True)\n",
    "                #print(\"C\", dffd[\"Coverage\"].values[-1], dffd[\"Accuracy\"].values[-1])\n",
    "\n",
    "\n",
    "            #duplicates x Achse loswerden und y dabei korrekt lassen\n",
    "            df_dup = pd.DataFrame({'Coverage': dffd[\"Coverage\"].values, 'Accuracy': dffd[\"Accuracy\"].values})\n",
    "            df_unique = df_dup.drop_duplicates(subset='Coverage', keep='first')\n",
    "                            \n",
    "            x,y = df_unique['Coverage'], df_unique['Accuracy']\n",
    "            interp_func = interp1d(x,y, kind='linear', fill_value='extrapolate')\n",
    "            #new_coverage = np.linspace(0, 1, 21)\n",
    "            \n",
    "            part1 = np.linspace(0, 0.9, int(0.9 / 0.05) + 1)\n",
    "            part2 = np.linspace(0.91, 1, int((1 - 0.9) / 0.01) + 1)\n",
    "            new_coverage = np.concatenate((part1, part2)) #Coverage in 1% bis 0.9 dann in 5%\n",
    "            \n",
    "            interpolated_accuracy = interp_func(new_coverage)\n",
    "            \n",
    "            #####SCORE BERECHNUNG -> AREA UNDER CURVE APPROX mit Simps (zeiteffizient, non kontinuirliche Funktion...)\n",
    "\n",
    "            new_coverage_for_integration_x = np.linspace(0.5, 1.0, 1000)\n",
    "            Score_50 = simps(interp_func(new_coverage_for_integration_x), new_coverage_for_integration_x) \n",
    "            new_coverage_for_integration_x = np.linspace(0.9, 1.0, 1000)\n",
    "            Score_90 = simps(interp_func(new_coverage_for_integration_x), new_coverage_for_integration_x)\n",
    "            new_coverage_for_integration_x = np.linspace(0.95, 1.0, 1000)\n",
    "            Score_95 = simps(interp_func(new_coverage_for_integration_x), new_coverage_for_integration_x)\n",
    "            \n",
    "            ####\n",
    "            \n",
    "            if np.isnan(interpolated_accuracy).any():\n",
    "                print(methode_clf,dataset,\"ERROR\")\n",
    "\n",
    "            data = {\n",
    "                'Accuracy': interpolated_accuracy,\n",
    "                'Coverage': new_coverage,\n",
    "                #'Score' : [area]*len(new_coverage),\n",
    "                \"Method_Classifier\": [methode_clf]*len(new_coverage)\n",
    "            }\n",
    "            \n",
    "            dataset_interpol = dataset + \" Interpolated\"\n",
    "            new_interpolate = create_pandas_frame(data,dataset_interpol,methode,size,clf_name,alldata=\"True\")\n",
    "            interpolated_dataframes.append(new_interpolate)\n",
    "            #\"Method_Classifier\", \"Dataset\", \"Score\",\"Method\",\"Classifier\"\n",
    "            score_df.loc[len(score_df)] = [methode_clf,dataset_interpol,size,Score_50,Score_90,Score_95,methode,clf_name]\n",
    "        \n",
    "        \n",
    "\n",
    "interpolate_df = pd.concat(interpolated_dataframes, ignore_index=True)\n",
    "full_result_df = pd.concat([interpolate_df,df], ignore_index=True) #Berechneter Stuff + Raw Datensätze\n",
    "\n",
    "#Scores - Baseline (Most Frequent Class) + Stanartisieren\n",
    "#score_df\n",
    "score_df[\"Score_50_norm\"] = score_df[\"Score_50\"] #copy zum ersetzen\n",
    "score_df[\"Score_90_norm\"] = score_df[\"Score_90\"]\n",
    "score_df[\"Score_95_norm\"] = score_df[\"Score_95\"]\n",
    "\n",
    "for size in score_df.Data_size.unique():\n",
    "    for dataset in score_df.Dataset.unique(): # NUR FÜR INTERPOLATED ANWENDEN!\n",
    "        for scoretype in [\"Score_50\",\"Score_90\",\"Score_95\"]:\n",
    "            baseline_score = score_df[(score_df.Data_size == size) & (score_df.Dataset == dataset) & (score_df.Method == \"Most Frequent Class\")][scoretype]\n",
    "            if baseline_score.empty:\n",
    "                continue\n",
    "            baseline_score = baseline_score.values[0]\n",
    "            condition = (score_df.Data_size == size) & (score_df.Dataset == dataset)\n",
    "            score_df.loc[condition, scoretype] -= baseline_score\n",
    "            \n",
    "            #standartisieren\n",
    "            scores = score_df[(score_df.Data_size == size) & (score_df.Dataset == dataset)][scoretype].values\n",
    "            max_deviation = np.max(np.abs(scores))\n",
    "            standardized_scores = scores / max_deviation if max_deviation != 0 else scores\n",
    "            score_df.loc[(score_df.Data_size == size) & (score_df.Dataset == dataset), f\"{scoretype}_norm\"] = standardized_scores\n",
    "            #score_df.loc[(score_df.Data_size == size) & (score_df.Dataset == dataset), scoretype] = standardized_scores\n",
    "\n",
    "\n",
    "#Ranking Tabelle\n",
    "\n",
    "#noch für alle DATASET und Datasize\n",
    "pd_rank_list = []\n",
    "for dataset in score_df.Dataset.unique():\n",
    "    pd_ranking = pd.DataFrame(columns=[\"Dataset\",\"Method_50\",\"Method_90\",\"Method_95\",\"Score_50_norm\",\"Score_90_norm\",\"Score_95_norm\"])\n",
    "\n",
    "    for num in [\"50\",\"90\",\"95\"]:\n",
    "        scoretype = f\"Score_{num}_norm\"\n",
    "        methodtype = f\"Method_{num}\"\n",
    "\n",
    "        part = score_df[(score_df.Dataset ==dataset)&(score_df.Data_size ==max(full_result_df.Data_size.unique()))]\n",
    "        part = part.reset_index(drop=True)\n",
    "        sorted_index = np.argsort(part[scoretype])\n",
    "\n",
    "        sorted_score= part[scoretype][sorted_index].values\n",
    "        sorted_method = part[\"Method_Classifier\"][sorted_index].values\n",
    "        pd_ranking[scoretype] = sorted_score\n",
    "        pd_ranking[methodtype] = sorted_method\n",
    "        pd_ranking[\"Dataset\"] = dataset\n",
    "        #print(sorted_index)\n",
    "\n",
    "    pd_ranking = pd_ranking.iloc[::-1].reset_index(drop=True)\n",
    "    pd_rank_list.append(pd_ranking)\n",
    "    \n",
    "pd_ranking_full = pd.concat(pd_rank_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45766d0-7805-4268-967a-a3c214b57adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('evaluation_ranking_full.pkl', 'wb') as f:\n",
    "    pickle.dump(pd_ranking_full, f)\n",
    "\n",
    "with open('evaluation_full.pkl', 'wb') as f:\n",
    "    pickle.dump(full_result_df, f)\n",
    "\n",
    "time_result.rename(columns={'Method': 'Method_Classifier'}, inplace=True)\n",
    "score_time_df = pd.merge(score_df, time_result, on=['Method_Classifier', 'Data_size', 'Dataset'], how='inner')\n",
    "with open('evaluation_time_full.pkl', 'wb') as f:\n",
    "    pickle.dump(score_time_df, f)\n",
    "\n",
    "with open('evaluation_roc.pkl', 'wb') as f:\n",
    "    pickle.dump(big_ROC_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
